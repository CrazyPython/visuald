<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">
<html lang='en-US'>

<!--
	Copyright (c) 1999-2010 by Digital Mars
	All Rights Reserved Written by Walter Bright
	http://www.digitalmars.com
  -->

<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8" >
<title>Concurrent Garbage Collection (on Windows) - D Programming Language - Digital Mars</title>
<link rel="stylesheet" type="text/css" href="http://www.dlang.org/css/codemirror.css" />
<link rel="stylesheet" type="text/css" href="http://www.dlang.org/css/style.css">

</head>

<body class='hyphenate'>

<div id="top">
	<div id="header">
		<a href="http://www.dlang.org"><img id="logo" width="125" height="95" border="0" alt="D Logo" src="http://www.dlang.org/images/dlogo.png"></a>
		<a id="d-language" href="http://www.dlang.org">D Programming Language - Rainer Schuetze</a>
	</div>
</div>

<div id="navigation">
    
<div class="navblock">
<div id="toctop">
    <ul><h2><a href="http://www.dlang.org/index.html" title="D Programming Language">D</a></h2>
	<li><a href="http://www.dlang.org/download.html" title="Download a D compiler">Downloads &amp; Tools</a></li>
	<li><a href="http://www.dlang.org/spec.html" title="D Language Specification">Language</a></li>
	<li><a href="http://www.dlang.org/phobos/index.html" title="D Runtime Library">Runtime Library </a></li>
    <li><a href="http://rainers.github.io/visuald/visuald/StartPage.html" title="Visual Studio Plugin for D">Visual D</a></li>
    </ul>

</div>
</div>


<div class="navblock">
<h2>Community</h2>
<ul>
	<li><a href="http://forum.dlang.org/" title="User forums">Forums</a></li>

	<li><a href="http://github.com/D-Programming-Language" title="D on github">GitHub</a></li>

	<li><a href="http://wiki.dlang.org" title="Wiki for the D Programming Language">Wiki</a></li>

	<li><a href="http://wiki.dlang.org/Review_Queue" title="Queue of current and upcoming standard library additions">Review Queue</a></li>

	<li><a href="http://twitter.com/#search?q=%23d_lang" title="#d_lang on twitter.com">Twitter</a></li>

</ul>

</div>


</div><!--/navigation-->
<div id="content">
    <h1>Concurrent Garbage Collection (on Windows)</h1>
    <div id=quickindex class=quickindex></div>
    <!-- Generated by Ddoc from concurrentgc.dd -->


<p>One of the most annoying properties of the current garbage collector
used by the D programming language is that it needs to "stop-the-world"
when running its collection. An application that has allocated a few 
hundreds MB of GC managed memory will experience pause times of some
seconds, even on modern hardware.
</p>

<p>The last couple of days I experimented with some ideas how to
realize a concurrent garbage collection (as implemented by
Leandro Lucarella for Linux [1]) on Windows. The linux version uses
"fork" to create an exact snapshot of the running process, which
can then be used to find unreferenced objects at the time of the
snapshot while the process can continue to mutate memory (using
copy-on-write page protection by the virtual memory management
of the OS).
</p>

<h2>Fork on Windows?</h2>

<p>Unfortunately, Windows does not have "fork". The closest match
is using VirtualProtect with page protection PAGE_WRITECOPY.
This only works on a file mapping object created with CreateFileMapping [3] 
that also allows sharing with another process using MapViewOfFile [4]. You don't
have to back
it up with an actual file, but you can also use the paging file. As
far as I can tell, no file I/O is happening if you have enough
memory to do this.
</p>

<p>So here is a plan: create a child process, allocate GC managed
memory using CreateFileMapping, so it can be shared with the child process.
When starting a collection, use VirtualProtect to set the memory
to copy-on-write. This works as expected for the first collection,
but some pages have been duplicated by COW in the application process. How do 
you get the state of these pages back into the shared memory view?
There seems to be no efficient way to do it using the virtual
memory manager.
</p>

<p>One slow way out could be to map the shared memory again, then copy the modified pages
into this view. But there might be still references into them, so you cannot release 
the modified pages. In the long run this ends up with all the memory having a non-shared copy 
in the other process. 
</p>
<p>What you really want is the reverse behaviour: make a copy of the pages
before the modification and use this copy during collection in the other process.
When the collection is done these copies can just be thrown away without
affecting the application.
</p>

<p>Another issue is how to detect modified pages:
there is a function GetWriteWatch that does exactly that in combination with ResetWriteWatch,
but it only works on memory
allocated with VirtualAlloc using the MEM_WRITE_WATCH flag. It
cannot be applied later to shared memory created with CreateFileMapping.
Using QueryWorkingSet to detect whether a page is still shared
seems to work, though you'll have to walk all the pages yourself.
</p>

<h2>COW on Windows?</h2>

<p>So let's get some benchmarks first to estimate the cost of copy-on-write. Ignoring initial
cache effects, here are the results for the first write access to a page (the code can
be found here <a href="https://github.com/rainers/druntime/blob/concurrent_gc2/benchmark/gcbench/cowbench.d">[7]</a>):
</p>

<div align="center">
        <table width="90%" style="border: 1px solid #ccc;margin: 0 0 0em 0em;" bgcolor="#F0F0F0">
        
<tr><td valign=top>page allocated with VirtualAlloc:                        </td> <td valign=top>1800 cycles</td></tr>
<tr><td valign=top>page allocated with VirtualAlloc+MEM_WRITE_WATCH:        </td> <td valign=top>1800 cycles</td></tr>
<tr><td valign=top>page allocated with VirtualAlloc+ResetWriteWatch:        </td> <td valign=top>1100 cycles</td></tr>
<tr><td valign=top>page allocated with CreateFileMapping+MapViewOfFile:     </td> <td valign=top>2200 cycles</td></tr>
<tr><td valign=top>page allocated with CreateFileMapping+MapViewOfFile+COW: </td> <td valign=top>4600 cycles</td></tr>

        </table>
    </div>

<p>[These numbers were measured on Win 8.1/64 with a mobile Intel
processor (i7-2670QM @ 2.2 GHz). Getting reliable numbers on it doesn't work too well,
although I use a power-scheme
of minimum and maximum processor state set to 99% to avoid the processor
changing core frequency, using Turbo Boost or disabling too many components. Still,
averaged values vary quite a bit from run to run. The shown values are typical
rounded minimum results over 1024 pages. The observed average values are usually
10 - 20 % above the minimum.]
</p>

<p>The values don't seem to vary much between 32-bit and 64-bit processes.
Coincidentally, Linus Torvalds very recently measured the time for a page fault 
on linux [6], with the result of a bit more than 1000 cycles.
</p>

<p>Seeing quite some penalty for copy-on-write by the OS, I considered doing the 
copy-on-write in a user exception handler for a write to a read-only page
aswell (ignoring the fact that this will ruin the debugging experience). This
would allow customizing the behaviour as mentioned above. Capturing writes to
protected pages should be handled before going through any other exception handlers,
so hooking the user mode callback for exceptions seems the fastest feasible way.
</p>

<p>Here are the benchmark results for different kind of exception handlers (these
actually don't do a full copy of the page but just change the address register
to point to writable memory - according to the measurements above copying 
the page takes more than 2000 cycles if done by the OS):
</p>

<div align="center">
        <table width="90%" style="border: 1px solid #ccc;margin: 0 0 0em 0em;" bgcolor="#F0F0F0">
        
<tr><td valign=top>                                                       </td> <td valign=top>         Win32</td> <td valign=top>         Win64</td> </tr>
<tr><td valign=top>User mode callback for page fault exceptions:          </td> <td valign=top>  28000 cycles</td> <td valign=top>   7000 cycles</td> </tr>
<tr><td valign=top>Page fault handled by the first SEH exception handler: </td> <td valign=top>  30000 cycles</td> <td valign=top>  not measured</td> </tr>
<tr><td valign=top>Page fault handled by catch(Throwable):                </td> <td valign=top>4000000 cycles</td> <td valign=top>   unavailable</td> </tr>
<tr><td valign=top>A standard D exception using try { throw } catch:      </td> <td valign=top>  18500 cycles</td> <td valign=top>   4200 cycles</td> </tr>

        </table>
    </div>

<p>Please note that the dmd exception handler for Win64 uses a non-native format that avoids the OS exception mechanism.
Therefore, capturing page faults does not work there.
</p>

<h2>Concurrency in the GC</h2>

<p>While the results for dealing with COW issues in the process itself seems possible for Win64, the overhead
for 32-bit processes is considerable. 
Writing a driver for Win32 that deals with these issues in kernel space
could be possible with similar performance as the OS, but having to install it with every application
written in D is inappropriate.
</p>

<p>A slightly different approach is inspired by the existence of GetWriteWatch and its quite good performance:
when a collection is needed (e.g. no more free memory available),
<ul>    <li>take a snapshot of the roots and reset the write watches. </li>
    <li>Trigger a background thread to mark the heap starting from the roots. Normal program flow can 
         continue including allocating new memory. </li>
    <li>Once it is finished, take a new snapshot of the roots and rescan modified pages. This assumes that 
         only few new references have been added, so most of the work has already been done. </li>
    <li>sweep unreferenced objects </li>
</ul>
</p>

<p>This will results in objects staying alive that were referenced either when taking the first or the
second snapshot.
</p>

<h3>Current GC</h3>

In a nutshell, this is how the current D runtime GC works:

<ul>    <li>memory is organized in a number of pools, each handling a contiguous memory area.
         Bit flags are used to describe the allocations inside this memory block:</li>
    <ul>
        <li>finals      : entries that need finalizer run on them </li>
        <li>noscan      : entries that should not be scanned </li>
        <li>appendable  : entries that are appendable </li>
        <li>nointerior  : interior pointers should be ignored (Only implemented for large object pools) </li>
    </ul>

    During collection, 3 more bits are used:
    <ul>
        <li>mark        : entries already scanned, or should not be scanned </li>
        <li>scan        : entries that need to be scanned </li>
        <li>freebits    : entries that are on the free list </li>
    </ul>

    <li>there are free-lists for objects sizes that are a power of 2. New allocations draw
         from these lists, create new lists from free pages inside a pool, or trigger a collection
         if there are no more free pages available</li>
    <li>when an allocation cannot be served, a full "stop-the-world" mark-and-sweep collection is run:
    <ul>
        <li>stop the world</li>
        <li>prepare: scan = false, rebuild free from free-lists, mark = free </li>
        <li>mark roots: for all entries referenced by stacks/registers/roots/ranges: mark-refs() </li>
        <li>scan heap: if scan { scan = 0, mark-refs() } </li>
        <li>sweep:   if !mark { if finals { finalizer() }, free = true } </li>
        <li>recover: clear free-lists, if free, add to free-list </li>
        <li>resume the world</li>
    </ul>

        mark-refs(): for all references found in the entry: 
        if !mark { mark = true; if !noscan { if recurse mark-refs(), else scan = true } } 
    </li>
</ul>


<h3>Concurrency in the GC</h3>

<p>With the building blocks of the current implementation, this is a more detailed description
of a concurrent GC:
</p>

<ul>
    <li>create a background thread for the mark phase</li>
    <li>allocate GC managed memory with VirtualAlloc and MEM_WRITE_WATCH</li>

    <li>when a collection seems necessary:
    <ul>
        <li>if the background GC is still active
        <ul>
            <li>continue with allocating a new pool</li>
        </ul>
</li>
        <li>else
        <ul>
            <li>stop the world</li>
            <li>if the background GC is done with a previous mark
            <ul>
                <li>mark all the roots that are active now</li>
                <li>mark references from pages that have been written to since the last reset</li>
                <li>scan heap for new references by new roots/modified pages
                  (in the hope that there are only a few left. if the number of new references
                   exceeds some threshold, this could be delegated to the background thread again) </li>
                <li>resume the world</li>
                <li>sweep unreferenced objects and recover empty pages/pools
                  (this could be deferred into allocations that reuse the memory) </li>
            </ul>
</li>
            <li>else
            <ul>
                <li>collect all roots: scan stacks/registers/roots/ranges and record to array </li>
                <li>reset write watches on GC managed memory</li>
                <li>prepare scanning </li>
                <li>trigger the background thread</li>
                <li>resume the world</li>
            </ul>
</li>
            <li>continue with what was freed by sweep/recover</li>
        </ul>
</li>
    </ul>
</li>
    
    <li>the background thread waits to be triggered, then
    <ul>
        <li>mark collected roots</li>
        <li>scan heap </li>
    </ul>
</li>
</ul>


<h3>Shared data structures</h3>

<p>The GC calls by the user are stll synchronized with a global lock, so all
user threads can be considered a single main thread. While the background thread
is running a mark phase, the main thread still modifies pool memory and data
structures. Without additional synchronization, consistent reading and writing to these
structures from different threads has to be guaranteed. </p>

<ul>    <li>the GC thread reads, but does not write the pool table, the freebits and noscan bitsets.</li>
    <li>the main and the GC thread never read/write the mask/scan bits simultaniously.</li>
    <li>heap memory is read by the GC thread, but might be written to by the main thread.
         All modified pages are rescanned in the second heap scan with the stopped world.
         (Only objects marked alive by the background thread have to be sanned.) </li>
</ul>


<p>Implementation details:</p>
<ul>
    <li>the pool table is now preallocated to avoid accessing it while being reallocated</li>
    <li>the freebits flags have to mantained during a collection to account for new allocations
         when doing the second heap scan
    <ul>
        <li>prepare: now sets all free bits</li>
        <li>malloc: clears free bit </li>
        <li> sweep: clears free bit for marked objects </li>
    </ul>
</li>
</ul>



<h3>Interaction with GC calls on a user thread during collection</h3>

<p>The user API to the GC has the following operations:
</p>
<ul>
    <li> malloc:  clears freebits: OK</li>
    <li> realloc:</li>
    <li> extend:</li>
    <li> free:    object added to free-list, but freebits unchanged</li>
    <li> setAttr/clrAttr/getAttr</li>
    <li> enable/disable</li>
    <li> reserve</li>
    <li> addrOf/sizeOf/query: only queries objects: OK</li>
    <li> addRoot/removeRoot: roots transferred synchronized: OK</li>
    <li> addRange/removeRange: roots in ranges transferred synchronized: OK</li>
    <li> fullCollect/minimze</li>
</ul>


<p>Concurrent operations not marked "OK" still have to be analyzed for these functions.
</p>

<h2>Implementation of a concurrent GC</h2>

<p>You can find an implementation of this cuncurrent GC here: <a href="https://github.com/rainers/druntime/tree/concurrent_gc2">https://github.com/rainers/druntime/tree/concurrent_gc2</a>
</p>

<p>Comparing the result of the benchmark suite <a href="https://github.com/rainers/druntime/tree/gc_bench/benchmark">https://github.com/rainers/druntime/tree/gc_bench/benchmark</a>
this is the result for Win64:
</p>

<div align="center">
        <table width="90%" style="border: 1px solid #ccc;margin: 0 0 0em 0em;" bgcolor="#F0F0F0">
        <tr><th></th><th colspan=3>Standard</th><th colspan=3>Concurrent</th></tr>
<tr><th>Test             </th> <th>ExecTime</th> <th>Memory</th>  <th>PauseTime</th> <th>ExecTime</th>  <th>Memory</th> <th>PauseTime</th></tr>
<tr><td valign=top>bh.d             </td> <td valign=top>11.121 s</td> <td valign=top>  25 MB</td> <td valign=top>  1933 ms</td> <td valign=top> 10.706 s</td> <td valign=top> 256 MB</td> <td valign=top> 1248 ms</td></tr>
<tr><td valign=top>bigarr.d         </td> <td valign=top> 5.529 s</td> <td valign=top>  36 MB</td> <td valign=top>  4067 ms</td> <td valign=top>  3.136 s</td> <td valign=top> 480 MB</td> <td valign=top> 1357 ms</td></tr>
<tr><td valign=top>bisort.d         </td> <td valign=top> 1.025 s</td> <td valign=top>  36 MB</td> <td valign=top>    68 ms</td> <td valign=top>  1.041 s</td> <td valign=top>  36 MB</td> <td valign=top>   16 ms</td></tr>
<tr><td valign=top>conalloc.d       </td> <td valign=top> 2.209 s</td> <td valign=top>   9 MB</td> <td valign=top>   347 ms</td> <td valign=top>  2.273 s</td> <td valign=top> 544 MB</td> <td valign=top>   28 ms</td></tr>
<tr><td valign=top>concpu.d         </td> <td valign=top> 4.216 s</td> <td valign=top>   4 MB</td> <td valign=top>  2408 ms</td> <td valign=top>  2.257 s</td> <td valign=top> 544 MB</td> <td valign=top>  119 ms</td></tr>
<tr><td valign=top>em3d.d           </td> <td valign=top> 3.176 s</td> <td valign=top> 169 MB</td> <td valign=top>  1339 ms</td> <td valign=top>  2.669 s</td> <td valign=top> 169 MB</td> <td valign=top>  440 ms</td></tr>
<tr><td valign=top>huge_single.d    </td> <td valign=top> 0.089 s</td> <td valign=top>   1 MB</td> <td valign=top>     0 ms</td> <td valign=top>  0.024 s</td> <td valign=top>   1 MB</td> <td valign=top>    0 ms</td></tr>
<tr><td valign=top>mcore.d          </td> <td valign=top> 0.110 s</td> <td valign=top>  81 MB</td> <td valign=top>     4 ms</td> <td valign=top>  0.221 s</td> <td valign=top> 100 MB</td> <td valign=top>    9 ms</td></tr>
<tr><td valign=top>rand_large.d     </td> <td valign=top> 2.250 s</td> <td valign=top>  81 MB</td> <td valign=top>  1132 ms</td> <td valign=top>  0.639 s</td> <td valign=top>2112 MB</td> <td valign=top>  185 ms</td></tr>
<tr><td valign=top>rand_small.d     </td> <td valign=top> 1.024 s</td> <td valign=top>  16 MB</td> <td valign=top>   421 ms</td> <td valign=top>  2.091 s</td> <td valign=top> 576 MB</td> <td valign=top>  130 ms</td></tr>
<tr><td valign=top>sbtree.d         </td> <td valign=top> 0.032 s</td> <td valign=top>   1 MB</td> <td valign=top>     0 ms</td> <td valign=top>  0.125 s</td> <td valign=top>   1 MB</td> <td valign=top>    0 ms</td></tr>
<tr><td valign=top>split.d          </td> <td valign=top> 0.885 s</td> <td valign=top> 778 MB</td> <td valign=top>     3 ms</td> <td valign=top>  1.119 s</td> <td valign=top> 819 MB</td> <td valign=top>  154 ms</td></tr>
<tr><td valign=top>testgc3.d        </td> <td valign=top>28.667 s</td> <td valign=top> 672 MB</td> <td valign=top> 17077 ms</td> <td valign=top> 15.650 s</td> <td valign=top> 896 MB</td> <td valign=top> 2485 ms</td></tr>
<tr><td valign=top>tree1.d          </td> <td valign=top>30.871 s</td> <td valign=top> 169 MB</td> <td valign=top> 16818 ms</td> <td valign=top> 21.286 s</td> <td valign=top> 896 MB</td> <td valign=top> 6184 ms</td></tr>
<tr><td valign=top>tree2.d          </td> <td valign=top> 0.259 s</td> <td valign=top>   1 MB</td> <td valign=top>    30 ms</td> <td valign=top>  0.354 s</td> <td valign=top>  25 MB</td> <td valign=top>   18 ms</td></tr>
<tr><td valign=top>tsp.d            </td> <td valign=top> 1.312 s</td> <td valign=top>  81 MB</td> <td valign=top>   261 ms</td> <td valign=top>  1.195 s</td> <td valign=top>  81 MB</td> <td valign=top>   50 ms</td></tr>
<tr><td valign=top>voronoi.d        </td> <td valign=top> 4.384 s</td> <td valign=top> 144 MB</td> <td valign=top>  3199 ms</td> <td valign=top>  1.749 s</td> <td valign=top> 288 MB</td> <td valign=top>  346 ms</td></tr>
<tr><td valign=top>bulk.d           </td> <td valign=top>142.11 s</td> <td valign=top>1346 MB</td> <td valign=top> 74018 ms</td> <td valign=top> 97.032 s</td> <td valign=top>3365 MB</td> <td valign=top>22002 ms</td></tr>
<tr><td valign=top>resize.d         </td> <td valign=top> 1.863 s</td> <td valign=top>   9 MB</td> <td valign=top>     2 ms</td> <td valign=top>  1.938 s</td> <td valign=top>   9 MB</td> <td valign=top>    1 ms</td></tr>
<tr><td valign=top>string.d         </td> <td valign=top> 0.074 s</td> <td valign=top>   9 MB</td> <td valign=top>     3 ms</td> <td valign=top>  0.464 s</td> <td valign=top>   9 MB</td> <td valign=top>    3 ms</td></tr>

        </table>
    </div>

<p>Most of the applications are faster with the concurrent GC than with the traditional 
implementation, mostly by shorter pause times, i.e. the time the application thread is
stopped by the GC. This comes at the cost of much higher memory usage for appliations
that allocate faster than the GC can find unused memory. Some performance
gain is also the result of fewer collections being run.
</p>



<p>Links:
</p>

<ul>
    <li>[1] <a href="http://llucax.com.ar/proj/dgc/index.html ">http://llucax.com.ar/proj/dgc/index.html </a> </li>
    <li>[2] <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa366898%28v=vs.85%29.aspx ">http://msdn.microsoft.com/en-us/library/windows/desktop/aa366898%28v=vs.85%29.aspx </a> </li>
    <li>[3] <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa366537%28v=vs.85%29.aspx ">http://msdn.microsoft.com/en-us/library/windows/desktop/aa366537%28v=vs.85%29.aspx </a> </li>
    <li>[4] <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa366761%28v=vs.85%29.aspx ">http://msdn.microsoft.com/en-us/library/windows/desktop/aa366761%28v=vs.85%29.aspx </a> </li>
    <li>[5] <a href="http://msdn.microsoft.com/en-us/library/windows/desktop/ms684946%28v=vs.85%29.aspx ">http://msdn.microsoft.com/en-us/library/windows/desktop/ms684946%28v=vs.85%29.aspx </a> </li>
    <li>[6] <a href="https://plus.google.com/+LinusTorvalds/posts/YDKRFDwHwr6 ">https://plus.google.com/+LinusTorvalds/posts/YDKRFDwHwr6 </a> </li>
    <li>[7] <a href="https://github.com/rainers/druntime/blob/concurrent_gc2/benchmark/gcbench/cowbench.d ">https://github.com/rainers/druntime/blob/concurrent_gc2/benchmark/gcbench/cowbench.d </a></li>
</ul>



</div><!--/content-->


<div id="copyright">
Copyright &copy; 2010-2014 by Rainer Schuetze, All Rights Reserved
 |
Page generated by <a href="http://www.digitalmars.com/d/2.0/ddoc.html">Ddoc</a>.
</div>

</body>
</html>

